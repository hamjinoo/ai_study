# GPT3_2020

- 최근 연구들은 방대한 텍스트 데이터를 사전 학습(Pre-training) 한 뒤 **특정 과제에 맞게 미세조정(fine-tuning)** 하면 여러 NLP 과제와 벤치마크에서 큰 성과를 낼 수 있음을 보여주었다.

  - AI를 먼저 책(인터넷 문서)으로 잔뜩 공부시키고, 나중에 시험(특정 과제)에 맞춰 조금만 더 학습 시키면 성적이 확 오르는 방식이다.

- 이 방식은 보통 특정 과제에 맞춰진 구조가 아닌 일반적인 아키텍처(범용)를 사용하지만, 여전히 **수천~수만 개의 과제별 데이터**가 필요하다

  - 범용적이긴 하나 실제로 시험을 잘 보려면 기출문제를 엄청나게 풀어야 한다는 의미

- 반대로, 인간은 몇 가지 예시나 간단한 지시만으로 새로운 언어 과제를 수행할 수 있는데, 이는 현재 NLP 시스템이 어려워 하는 부분이다.

  - "이 문장이 왜 슬플까?" 라고 말할 때 AI는 말할 수 있는 유연성이 부족하다.

- 이 논문에서 **언어 모델을 크게 확장**하면 과제 특화가 아닌 상태에서도 **few-shot 학습 성능**이 크게 개선되며, 때로는 **최신 미세조정 기법과 경쟁**할 정도에 이른다는 것을 보인다.

  - AI를 단순히 더 크게 만들면, 몇 개의 예시만으로도 기존의 정식 훈련 방식과 맞먹을 수 있다.
  - Scaling up(확장): 모델 크기 키우기
  - Few-shot learning (소수 예시 학습)

- 구체적으로, **1750억 개의 파라미터를 가진 자기회귀 언어 모델 GPT-3**를 훈련했으며, 이는 이전의 비희소(non-sparse) 언어 모델보다 10배 큰 규모이고, few-shot 환경에서 그 성능을 시험했다.

  - GPT-3라는 초거대 AI를 만들었고, 몇 개 예시만 주고 얼마나 잘 하는지 실험했다.

- 모든 과제에서 GPT-3는 **추가 학습 없이,** 단지 텍스트로 주어진 지시와 예시만으로 수행되었다.

- 번역, 질의응답, 빈칸 채우기 같은 여러 NLP 과제에서 강력한 성능을 보였으며, 단어 재배열, 새로운 단어 활용, 세 자리 수 연산 같은 즉석 추론이나 분야 적응 과제에서도 좋은 성과를 냈다.

- 일부 데이터셋에서는 few-shot 학습에 여전히 어려움을 겪었으며, 대규모 웹 데이터로 학습한 데서 비롯된 방법론적 문제도 확인되었다.

- 마지막으로, GPT-3가 만든 뉴스 기사 샘플은 **사람 평가자가 진짜 기사와 구분하기 어려울 정도**로 사실적이었다.

- 우리는 이러한 발견과 GPT-3 전반이 사회에 미칠 더 광범위한 영향을 논의한다.

> GPT-3는 1750억 파라미터의 초거대 언어 모델로, few-shot 학습만으로도 번역·질의응답·추론 등 다양한 과제를 잘 수행했지만, 일부 한계와 사회적 위험도 함께 드러났다

---
