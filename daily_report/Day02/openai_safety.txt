오픈AI는 최근 모델 안전성 강화를 위한 새로운 연구 결과를 발표했다.
연구팀은 프롬프트 인젝션 공격을 방어하기 위한 필터링 기법을 제시했으며, 
사용자 입력 검증과 응답 모니터링을 통해 보안성을 높이고 있다.
또한, 평가 프레임워크를 도입해 모델이 정확성과 안전성 기준을 충족하는지 지속적으로 점검하고 있다.
이는 AI 신뢰성과 책임성 확보를 위한 핵심 단계로 평가된다.
